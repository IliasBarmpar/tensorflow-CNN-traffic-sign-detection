{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = \"Train\"\n",
    "data_list = []\n",
    "labels_list = []\n",
    "classes_list = 43\n",
    "label_size_list = []\n",
    "for i in range(classes_list):\n",
    "    i_path = os.path.join(imgs_path, str(i))\n",
    "    label_size_list.append({i, len(os.listdir(i_path))})\n",
    "    for img in os.listdir(i_path):\n",
    "        im = Image.open(i_path +'/'+ img)\n",
    "        im = im.resize((32,32))\n",
    "        im = np.array(im)\n",
    "        data_list.append(im)\n",
    "        labels_list.append(i)\n",
    "data = np.array(data_list)\n",
    "labels = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 210},\n",
       " {1, 2220},\n",
       " {2, 2250},\n",
       " {3, 1410},\n",
       " {4, 1980},\n",
       " {5, 1860},\n",
       " {6, 420},\n",
       " {7, 1440},\n",
       " {8, 1410},\n",
       " {9, 1470},\n",
       " {10, 2010},\n",
       " {11, 1320},\n",
       " {12, 2100},\n",
       " {13, 2160},\n",
       " {14, 780},\n",
       " {15, 630},\n",
       " {16, 420},\n",
       " {17, 1110},\n",
       " {18, 1200},\n",
       " {19, 210},\n",
       " {20, 360},\n",
       " {21, 330},\n",
       " {22, 390},\n",
       " {23, 510},\n",
       " {24, 270},\n",
       " {25, 1500},\n",
       " {26, 600},\n",
       " {27, 240},\n",
       " {28, 540},\n",
       " {29, 270},\n",
       " {30, 450},\n",
       " {31, 780},\n",
       " {32, 240},\n",
       " {33, 689},\n",
       " {34, 420},\n",
       " {35, 1200},\n",
       " {36, 390},\n",
       " {37, 210},\n",
       " {38, 2070},\n",
       " {39, 300},\n",
       " {40, 360},\n",
       " {41, 240},\n",
       " {42, 240}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_size_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(data, labels,test_size=0.2, random_state=2)\n",
    "\n",
    "x_train = x_train/255\n",
    "x_val = x_val/255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 43)\n",
    "y_val = keras.utils.to_categorical(y_val, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "981/981 [==============================] - 20s 20ms/step - loss: 2.3024 - accuracy: 0.3152 - f1_m: 0.1503 - val_loss: 1.3852 - val_accuracy: 0.5782 - val_f1_m: 0.2004\n",
      "Epoch 2/30\n",
      "981/981 [==============================] - 18s 19ms/step - loss: 1.3178 - accuracy: 0.5552 - f1_m: 0.2071 - val_loss: 0.7851 - val_accuracy: 0.7569 - val_f1_m: 0.2358\n",
      "Epoch 3/30\n",
      "981/981 [==============================] - 19s 19ms/step - loss: 0.9618 - accuracy: 0.6715 - f1_m: 0.2373 - val_loss: 0.5088 - val_accuracy: 0.8407 - val_f1_m: 0.2606\n",
      "Epoch 4/30\n",
      "981/981 [==============================] - 18s 18ms/step - loss: 0.7414 - accuracy: 0.7379 - f1_m: 0.2566 - val_loss: 0.3687 - val_accuracy: 0.8951 - val_f1_m: 0.2867\n",
      "Epoch 5/30\n",
      "981/981 [==============================] - 17s 17ms/step - loss: 0.6148 - accuracy: 0.7822 - f1_m: 0.2820 - val_loss: 0.2663 - val_accuracy: 0.9249 - val_f1_m: 0.3286\n",
      "Epoch 6/30\n",
      "981/981 [==============================] - 17s 18ms/step - loss: 0.5342 - accuracy: 0.8113 - f1_m: 0.2985 - val_loss: 0.2025 - val_accuracy: 0.9369 - val_f1_m: 0.3387\n",
      "Epoch 7/30\n",
      "981/981 [==============================] - 18s 18ms/step - loss: 0.4867 - accuracy: 0.8258 - f1_m: 0.3120 - val_loss: 0.1863 - val_accuracy: 0.9431 - val_f1_m: 0.3475\n",
      "Epoch 8/30\n",
      "981/981 [==============================] - 18s 19ms/step - loss: 0.4389 - accuracy: 0.8387 - f1_m: 0.3245 - val_loss: 0.1503 - val_accuracy: 0.9512 - val_f1_m: 0.3701\n",
      "Epoch 9/30\n",
      "981/981 [==============================] - 17s 18ms/step - loss: 0.4120 - accuracy: 0.8508 - f1_m: 0.3426 - val_loss: 0.1411 - val_accuracy: 0.9565 - val_f1_m: 0.3853\n",
      "Epoch 10/30\n",
      "981/981 [==============================] - 16s 17ms/step - loss: 0.3959 - accuracy: 0.8590 - f1_m: 0.3490 - val_loss: 0.1211 - val_accuracy: 0.9614 - val_f1_m: 0.4029\n",
      "Epoch 11/30\n",
      "981/981 [==============================] - 17s 17ms/step - loss: 0.3607 - accuracy: 0.8682 - f1_m: 0.3625 - val_loss: 0.1120 - val_accuracy: 0.9633 - val_f1_m: 0.4149\n",
      "Epoch 12/30\n",
      "981/981 [==============================] - 18s 19ms/step - loss: 0.3555 - accuracy: 0.8686 - f1_m: 0.3693 - val_loss: 0.1049 - val_accuracy: 0.9670 - val_f1_m: 0.4302\n",
      "Epoch 13/30\n",
      "981/981 [==============================] - 18s 18ms/step - loss: 0.3375 - accuracy: 0.8752 - f1_m: 0.3842 - val_loss: 0.0920 - val_accuracy: 0.9736 - val_f1_m: 0.4454\n",
      "Epoch 14/30\n",
      "981/981 [==============================] - 17s 18ms/step - loss: 0.3280 - accuracy: 0.8796 - f1_m: 0.3890 - val_loss: 0.0826 - val_accuracy: 0.9748 - val_f1_m: 0.4613\n",
      "Epoch 15/30\n",
      "981/981 [==============================] - 17s 17ms/step - loss: 0.3165 - accuracy: 0.8839 - f1_m: 0.3983 - val_loss: 0.0736 - val_accuracy: 0.9795 - val_f1_m: 0.4628\n",
      "Epoch 16/30\n",
      "981/981 [==============================] - 17s 17ms/step - loss: 0.3046 - accuracy: 0.8891 - f1_m: 0.4123 - val_loss: 0.0794 - val_accuracy: 0.9772 - val_f1_m: 0.4835\n",
      "Epoch 17/30\n",
      "981/981 [==============================] - 17s 17ms/step - loss: 0.2897 - accuracy: 0.8918 - f1_m: 0.4203 - val_loss: 0.0800 - val_accuracy: 0.9731 - val_f1_m: 0.4960\n",
      "Epoch 18/30\n",
      "981/981 [==============================] - 18s 18ms/step - loss: 0.2934 - accuracy: 0.8958 - f1_m: 0.4300 - val_loss: 0.0695 - val_accuracy: 0.9799 - val_f1_m: 0.4848\n",
      "Epoch 19/30\n",
      "981/981 [==============================] - 18s 18ms/step - loss: 0.2873 - accuracy: 0.8987 - f1_m: 0.4410 - val_loss: 0.0681 - val_accuracy: 0.9801 - val_f1_m: 0.5076\n",
      "Epoch 20/30\n",
      "981/981 [==============================] - 17s 17ms/step - loss: 0.2845 - accuracy: 0.8969 - f1_m: 0.4481 - val_loss: 0.0641 - val_accuracy: 0.9821 - val_f1_m: 0.4984\n",
      "Epoch 21/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2775 - accuracy: 0.8995 - f1_m: 0.4526 - val_loss: 0.0562 - val_accuracy: 0.9833 - val_f1_m: 0.5410\n",
      "Epoch 22/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2805 - accuracy: 0.8995 - f1_m: 0.4623 - val_loss: 0.0591 - val_accuracy: 0.9813 - val_f1_m: 0.5414\n",
      "Epoch 23/30\n",
      "981/981 [==============================] - 14s 14ms/step - loss: 0.2614 - accuracy: 0.9052 - f1_m: 0.4764 - val_loss: 0.0588 - val_accuracy: 0.9825 - val_f1_m: 0.5414\n",
      "Epoch 24/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2618 - accuracy: 0.9067 - f1_m: 0.4761 - val_loss: 0.0509 - val_accuracy: 0.9846 - val_f1_m: 0.5502\n",
      "Epoch 25/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2585 - accuracy: 0.9082 - f1_m: 0.4803 - val_loss: 0.0534 - val_accuracy: 0.9856 - val_f1_m: 0.5634\n",
      "Epoch 26/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2543 - accuracy: 0.9107 - f1_m: 0.4958 - val_loss: 0.0663 - val_accuracy: 0.9764 - val_f1_m: 0.5661\n",
      "Epoch 27/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2547 - accuracy: 0.9107 - f1_m: 0.4998 - val_loss: 0.0547 - val_accuracy: 0.9821 - val_f1_m: 0.5809\n",
      "Epoch 28/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2555 - accuracy: 0.9096 - f1_m: 0.5017 - val_loss: 0.0528 - val_accuracy: 0.9832 - val_f1_m: 0.5816\n",
      "Epoch 29/30\n",
      "981/981 [==============================] - 14s 15ms/step - loss: 0.2496 - accuracy: 0.9114 - f1_m: 0.5107 - val_loss: 0.0445 - val_accuracy: 0.9874 - val_f1_m: 0.6061\n",
      "Epoch 30/30\n",
      "981/981 [==============================] - 15s 15ms/step - loss: 0.2455 - accuracy: 0.9117 - f1_m: 0.5137 - val_loss: 0.0483 - val_accuracy: 0.9860 - val_f1_m: 0.6040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23db410efe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (32, 32, 3)))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43 , activation = 'softmax')) \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , metrics=['accuracy',f1_m], optimizer = \"adam\")\n",
    "model.fit(x_train, y_train, epochs=30, verbose=1, validation_data=(x_val, y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 1.9708 - accuracy: 0.4244 - f1_m: 0.1644\n",
      "Epoch 1: val_loss improved from inf to 1.47079, saving model to best_model.h5\n",
      "246/246 [==============================] - 62s 252ms/step - loss: 1.9706 - accuracy: 0.4245 - f1_m: 0.1645 - val_loss: 1.4708 - val_accuracy: 0.5402 - val_f1_m: 0.2057\n",
      "Epoch 2/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 1.3273 - accuracy: 0.5869 - f1_m: 0.2241\n",
      "Epoch 2: val_loss improved from 1.47079 to 1.19044, saving model to best_model.h5\n",
      "246/246 [==============================] - 59s 242ms/step - loss: 1.3274 - accuracy: 0.5869 - f1_m: 0.2241 - val_loss: 1.1904 - val_accuracy: 0.6319 - val_f1_m: 0.2427\n",
      "Epoch 3/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 1.1024 - accuracy: 0.6552 - f1_m: 0.2494\n",
      "Epoch 3: val_loss improved from 1.19044 to 1.01552, saving model to best_model.h5\n",
      "246/246 [==============================] - 60s 244ms/step - loss: 1.1024 - accuracy: 0.6552 - f1_m: 0.2494 - val_loss: 1.0155 - val_accuracy: 0.6817 - val_f1_m: 0.2606\n",
      "Epoch 4/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.9567 - accuracy: 0.7005 - f1_m: 0.2680\n",
      "Epoch 4: val_loss improved from 1.01552 to 0.89804, saving model to best_model.h5\n",
      "246/246 [==============================] - 59s 240ms/step - loss: 0.9567 - accuracy: 0.7005 - f1_m: 0.2680 - val_loss: 0.8980 - val_accuracy: 0.7209 - val_f1_m: 0.2773\n",
      "Epoch 5/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.8463 - accuracy: 0.7348 - f1_m: 0.2794\n",
      "Epoch 5: val_loss improved from 0.89804 to 0.80505, saving model to best_model.h5\n",
      "246/246 [==============================] - 61s 247ms/step - loss: 0.8465 - accuracy: 0.7347 - f1_m: 0.2792 - val_loss: 0.8051 - val_accuracy: 0.7522 - val_f1_m: 0.2874\n",
      "Epoch 6/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.7714 - accuracy: 0.7586 - f1_m: 0.2919\n",
      "Epoch 6: val_loss improved from 0.80505 to 0.73917, saving model to best_model.h5\n",
      "246/246 [==============================] - 64s 260ms/step - loss: 0.7713 - accuracy: 0.7587 - f1_m: 0.2921 - val_loss: 0.7392 - val_accuracy: 0.7665 - val_f1_m: 0.2975\n",
      "Epoch 7/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.7811 - f1_m: 0.3001\n",
      "Epoch 7: val_loss improved from 0.73917 to 0.69593, saving model to best_model.h5\n",
      "246/246 [==============================] - 59s 240ms/step - loss: 0.6977 - accuracy: 0.7811 - f1_m: 0.3005 - val_loss: 0.6959 - val_accuracy: 0.7762 - val_f1_m: 0.3133\n",
      "Epoch 8/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.6436 - accuracy: 0.7967 - f1_m: 0.3073\n",
      "Epoch 8: val_loss improved from 0.69593 to 0.65845, saving model to best_model.h5\n",
      "246/246 [==============================] - 61s 247ms/step - loss: 0.6436 - accuracy: 0.7967 - f1_m: 0.3073 - val_loss: 0.6584 - val_accuracy: 0.7932 - val_f1_m: 0.3129\n",
      "Epoch 9/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.5919 - accuracy: 0.8153 - f1_m: 0.3150\n",
      "Epoch 9: val_loss improved from 0.65845 to 0.59863, saving model to best_model.h5\n",
      "246/246 [==============================] - 61s 246ms/step - loss: 0.5918 - accuracy: 0.8153 - f1_m: 0.3151 - val_loss: 0.5986 - val_accuracy: 0.8146 - val_f1_m: 0.3280\n",
      "Epoch 10/10\n",
      "245/246 [============================>.] - ETA: 0s - loss: 0.5507 - accuracy: 0.8280 - f1_m: 0.3226\n",
      "Epoch 10: val_loss improved from 0.59863 to 0.57475, saving model to best_model.h5\n",
      "246/246 [==============================] - 60s 242ms/step - loss: 0.5508 - accuracy: 0.8280 - f1_m: 0.3228 - val_loss: 0.5748 - val_accuracy: 0.8199 - val_f1_m: 0.3306\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model.trainable =  False\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(43, activation = 'softmax')(x)\n",
    "model = keras.Model(inputs,outputs)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) \n",
    "save_model = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy',f1_m])\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_val, y_val), shuffle = True, verbose=1, callbacks=[save_model]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning (VGG16) + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.8365 - accuracy: 0.4413 - f1_m: 0.2251\n",
      "Epoch 1: val_loss improved from inf to 1.56961, saving model to best_model.h5\n",
      "980/980 [==============================] - 74s 75ms/step - loss: 1.8365 - accuracy: 0.4413 - f1_m: 0.2251 - val_loss: 1.5696 - val_accuracy: 0.4941 - val_f1_m: 0.2524\n",
      "Epoch 2/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.3086 - accuracy: 0.5775 - f1_m: 0.2843\n",
      "Epoch 2: val_loss improved from 1.56961 to 1.48819, saving model to best_model.h5\n",
      "980/980 [==============================] - 77s 78ms/step - loss: 1.3086 - accuracy: 0.5775 - f1_m: 0.2843 - val_loss: 1.4882 - val_accuracy: 0.5168 - val_f1_m: 0.2736\n",
      "Epoch 3/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.1315 - accuracy: 0.6297 - f1_m: 0.3065\n",
      "Epoch 3: val_loss improved from 1.48819 to 1.35620, saving model to best_model.h5\n",
      "980/980 [==============================] - 76s 78ms/step - loss: 1.1315 - accuracy: 0.6297 - f1_m: 0.3065 - val_loss: 1.3562 - val_accuracy: 0.5496 - val_f1_m: 0.2991\n",
      "Epoch 4/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.6656 - f1_m: 0.3201\n",
      "Epoch 4: val_loss improved from 1.35620 to 1.33054, saving model to best_model.h5\n",
      "980/980 [==============================] - 78s 79ms/step - loss: 1.0138 - accuracy: 0.6656 - f1_m: 0.3201 - val_loss: 1.3305 - val_accuracy: 0.5698 - val_f1_m: 0.3003\n",
      "Epoch 5/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.9343 - accuracy: 0.6900 - f1_m: 0.3294\n",
      "Epoch 5: val_loss did not improve from 1.33054\n",
      "980/980 [==============================] - 67s 68ms/step - loss: 0.9343 - accuracy: 0.6900 - f1_m: 0.3294 - val_loss: 1.3761 - val_accuracy: 0.5634 - val_f1_m: 0.3149\n",
      "Epoch 6/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.8689 - accuracy: 0.7106 - f1_m: 0.3380\n",
      "Epoch 6: val_loss improved from 1.33054 to 1.22200, saving model to best_model.h5\n",
      "980/980 [==============================] - 62s 63ms/step - loss: 0.8689 - accuracy: 0.7106 - f1_m: 0.3380 - val_loss: 1.2220 - val_accuracy: 0.6053 - val_f1_m: 0.3225\n",
      "Epoch 7/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.8229 - accuracy: 0.7244 - f1_m: 0.3450\n",
      "Epoch 7: val_loss improved from 1.22200 to 1.21095, saving model to best_model.h5\n",
      "980/980 [==============================] - 64s 65ms/step - loss: 0.8229 - accuracy: 0.7244 - f1_m: 0.3450 - val_loss: 1.2110 - val_accuracy: 0.6071 - val_f1_m: 0.3225\n",
      "Epoch 8/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.7431 - f1_m: 0.3514\n",
      "Epoch 8: val_loss did not improve from 1.21095\n",
      "980/980 [==============================] - 66s 67ms/step - loss: 0.7711 - accuracy: 0.7431 - f1_m: 0.3514 - val_loss: 1.2580 - val_accuracy: 0.6035 - val_f1_m: 0.3340\n",
      "Epoch 9/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.7512 - f1_m: 0.3601\n",
      "Epoch 9: val_loss did not improve from 1.21095\n",
      "980/980 [==============================] - 69s 71ms/step - loss: 0.7404 - accuracy: 0.7512 - f1_m: 0.3601 - val_loss: 1.3154 - val_accuracy: 0.5881 - val_f1_m: 0.3359\n",
      "Epoch 10/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.7654 - f1_m: 0.3670\n",
      "Epoch 10: val_loss did not improve from 1.21095\n",
      "980/980 [==============================] - 69s 70ms/step - loss: 0.7012 - accuracy: 0.7654 - f1_m: 0.3670 - val_loss: 1.2620 - val_accuracy: 0.6113 - val_f1_m: 0.3580\n",
      "Epoch 11/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.7726 - f1_m: 0.3770\n",
      "Epoch 11: val_loss did not improve from 1.21095\n",
      "980/980 [==============================] - 67s 68ms/step - loss: 0.6809 - accuracy: 0.7726 - f1_m: 0.3770 - val_loss: 1.3316 - val_accuracy: 0.5951 - val_f1_m: 0.3465\n",
      "Epoch 12/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.7800 - f1_m: 0.3792\n",
      "Epoch 12: val_loss improved from 1.21095 to 1.19591, saving model to best_model.h5\n",
      "980/980 [==============================] - 68s 69ms/step - loss: 0.6512 - accuracy: 0.7800 - f1_m: 0.3792 - val_loss: 1.1959 - val_accuracy: 0.6223 - val_f1_m: 0.3569\n",
      "Epoch 13/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.7863 - f1_m: 0.3816\n",
      "Epoch 13: val_loss did not improve from 1.19591\n",
      "980/980 [==============================] - 67s 69ms/step - loss: 0.6288 - accuracy: 0.7863 - f1_m: 0.3816 - val_loss: 1.3016 - val_accuracy: 0.6062 - val_f1_m: 0.3615\n",
      "Epoch 14/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.7925 - f1_m: 0.3904\n",
      "Epoch 14: val_loss did not improve from 1.19591\n",
      "980/980 [==============================] - 74s 76ms/step - loss: 0.6099 - accuracy: 0.7925 - f1_m: 0.3904 - val_loss: 1.2337 - val_accuracy: 0.6199 - val_f1_m: 0.3657\n",
      "Epoch 15/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.8021 - f1_m: 0.3961\n",
      "Epoch 15: val_loss did not improve from 1.19591\n",
      "980/980 [==============================] - 75s 77ms/step - loss: 0.5880 - accuracy: 0.8021 - f1_m: 0.3961 - val_loss: 1.2745 - val_accuracy: 0.6251 - val_f1_m: 0.3714\n",
      "Epoch 16/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.8073 - f1_m: 0.4037\n",
      "Epoch 16: val_loss did not improve from 1.19591\n",
      "980/980 [==============================] - 79s 81ms/step - loss: 0.5677 - accuracy: 0.8073 - f1_m: 0.4037 - val_loss: 1.3044 - val_accuracy: 0.6153 - val_f1_m: 0.3730\n",
      "Epoch 17/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.8110 - f1_m: 0.4087\n",
      "Epoch 17: val_loss did not improve from 1.19591\n",
      "980/980 [==============================] - 73s 75ms/step - loss: 0.5623 - accuracy: 0.8110 - f1_m: 0.4087 - val_loss: 1.2171 - val_accuracy: 0.6413 - val_f1_m: 0.3723\n",
      "Epoch 18/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.8175 - f1_m: 0.4086\n",
      "Epoch 18: val_loss did not improve from 1.19591\n",
      "980/980 [==============================] - 72s 73ms/step - loss: 0.5373 - accuracy: 0.8175 - f1_m: 0.4086 - val_loss: 1.3810 - val_accuracy: 0.6051 - val_f1_m: 0.3827\n",
      "Epoch 19/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.8181 - f1_m: 0.4127\n",
      "Epoch 19: val_loss improved from 1.19591 to 1.15646, saving model to best_model.h5\n",
      "980/980 [==============================] - 71s 72ms/step - loss: 0.5350 - accuracy: 0.8181 - f1_m: 0.4127 - val_loss: 1.1565 - val_accuracy: 0.6426 - val_f1_m: 0.3913\n",
      "Epoch 20/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8222 - f1_m: 0.4201\n",
      "Epoch 20: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 71s 72ms/step - loss: 0.5253 - accuracy: 0.8222 - f1_m: 0.4201 - val_loss: 1.3780 - val_accuracy: 0.6121 - val_f1_m: 0.3996\n",
      "Epoch 21/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.8252 - f1_m: 0.4280\n",
      "Epoch 21: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 71s 73ms/step - loss: 0.5138 - accuracy: 0.8252 - f1_m: 0.4280 - val_loss: 1.3093 - val_accuracy: 0.6298 - val_f1_m: 0.3911\n",
      "Epoch 22/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.8326 - f1_m: 0.4239\n",
      "Epoch 22: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 73s 74ms/step - loss: 0.4928 - accuracy: 0.8326 - f1_m: 0.4239 - val_loss: 1.2693 - val_accuracy: 0.6287 - val_f1_m: 0.3993\n",
      "Epoch 23/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.8329 - f1_m: 0.4314\n",
      "Epoch 23: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 70s 72ms/step - loss: 0.4891 - accuracy: 0.8329 - f1_m: 0.4314 - val_loss: 1.2526 - val_accuracy: 0.6413 - val_f1_m: 0.4126\n",
      "Epoch 24/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.8355 - f1_m: 0.4344\n",
      "Epoch 24: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 68s 69ms/step - loss: 0.4810 - accuracy: 0.8355 - f1_m: 0.4344 - val_loss: 1.2726 - val_accuracy: 0.6410 - val_f1_m: 0.3975\n",
      "Epoch 25/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.8391 - f1_m: 0.4337\n",
      "Epoch 25: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 71s 72ms/step - loss: 0.4696 - accuracy: 0.8391 - f1_m: 0.4337 - val_loss: 1.3474 - val_accuracy: 0.6354 - val_f1_m: 0.4064\n",
      "Epoch 26/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.8399 - f1_m: 0.4404\n",
      "Epoch 26: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 74s 75ms/step - loss: 0.4659 - accuracy: 0.8399 - f1_m: 0.4404 - val_loss: 1.2819 - val_accuracy: 0.6398 - val_f1_m: 0.4235\n",
      "Epoch 27/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.8436 - f1_m: 0.4455\n",
      "Epoch 27: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 74s 75ms/step - loss: 0.4563 - accuracy: 0.8436 - f1_m: 0.4455 - val_loss: 1.2269 - val_accuracy: 0.6512 - val_f1_m: 0.4214\n",
      "Epoch 28/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.8431 - f1_m: 0.4488\n",
      "Epoch 28: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 74s 76ms/step - loss: 0.4542 - accuracy: 0.8431 - f1_m: 0.4488 - val_loss: 1.3788 - val_accuracy: 0.6375 - val_f1_m: 0.4364\n",
      "Epoch 29/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8483 - f1_m: 0.4548\n",
      "Epoch 29: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 73s 74ms/step - loss: 0.4416 - accuracy: 0.8483 - f1_m: 0.4548 - val_loss: 1.3410 - val_accuracy: 0.6408 - val_f1_m: 0.4217\n",
      "Epoch 30/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.8506 - f1_m: 0.4613\n",
      "Epoch 30: val_loss did not improve from 1.15646\n",
      "980/980 [==============================] - 75s 76ms/step - loss: 0.4329 - accuracy: 0.8506 - f1_m: 0.4613 - val_loss: 1.2958 - val_accuracy: 0.6446 - val_f1_m: 0.4300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23da50a80a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model.trainable =  False\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(43, activation = 'softmax')(x)\n",
    "model = keras.Model(inputs,outputs)\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  \n",
    "        samplewise_center=True,  \n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=False)\n",
    "        \n",
    "datagen.fit(x_train)\n",
    "\n",
    "save_model = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy',f1_m])\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "          steps_per_epoch=len(x_train) / 32, epochs=30, validation_data=(x_val, y_val), shuffle = True, callbacks=[save_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture 1 + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 2.6691 - accuracy: 0.2327 - f1_m: 0.1353\n",
      "Epoch 1: val_loss improved from inf to 3.27958, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 20ms/step - loss: 2.6685 - accuracy: 0.2329 - f1_m: 0.1353 - val_loss: 3.2796 - val_accuracy: 0.1598 - val_f1_m: 0.1548\n",
      "Epoch 2/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.9292 - accuracy: 0.3839 - f1_m: 0.1796\n",
      "Epoch 2: val_loss improved from 3.27958 to 2.95583, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 20ms/step - loss: 1.9290 - accuracy: 0.3838 - f1_m: 0.1797 - val_loss: 2.9558 - val_accuracy: 0.2045 - val_f1_m: 0.1819\n",
      "Epoch 3/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.5988 - accuracy: 0.4724 - f1_m: 0.1987\n",
      "Epoch 3: val_loss improved from 2.95583 to 2.79477, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 20ms/step - loss: 1.5991 - accuracy: 0.4724 - f1_m: 0.1987 - val_loss: 2.7948 - val_accuracy: 0.2817 - val_f1_m: 0.2286\n",
      "Epoch 4/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 1.3967 - accuracy: 0.5343 - f1_m: 0.2178\n",
      "Epoch 4: val_loss improved from 2.79477 to 2.55522, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 20ms/step - loss: 1.3965 - accuracy: 0.5343 - f1_m: 0.2178 - val_loss: 2.5552 - val_accuracy: 0.3481 - val_f1_m: 0.2228\n",
      "Epoch 5/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.2631 - accuracy: 0.5710 - f1_m: 0.2330\n",
      "Epoch 5: val_loss improved from 2.55522 to 2.12688, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 20ms/step - loss: 1.2631 - accuracy: 0.5710 - f1_m: 0.2330 - val_loss: 2.1269 - val_accuracy: 0.4126 - val_f1_m: 0.2483\n",
      "Epoch 6/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.1682 - accuracy: 0.6040 - f1_m: 0.2457\n",
      "Epoch 6: val_loss improved from 2.12688 to 1.70823, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 20ms/step - loss: 1.1683 - accuracy: 0.6038 - f1_m: 0.2457 - val_loss: 1.7082 - val_accuracy: 0.4892 - val_f1_m: 0.2665\n",
      "Epoch 7/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.0969 - accuracy: 0.6209 - f1_m: 0.2570\n",
      "Epoch 7: val_loss improved from 1.70823 to 1.51569, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 1.0964 - accuracy: 0.6211 - f1_m: 0.2570 - val_loss: 1.5157 - val_accuracy: 0.5383 - val_f1_m: 0.2879\n",
      "Epoch 8/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.0347 - accuracy: 0.6433 - f1_m: 0.2693\n",
      "Epoch 8: val_loss improved from 1.51569 to 1.46953, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 1.0347 - accuracy: 0.6433 - f1_m: 0.2693 - val_loss: 1.4695 - val_accuracy: 0.5737 - val_f1_m: 0.2843\n",
      "Epoch 9/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 0.9943 - accuracy: 0.6572 - f1_m: 0.2757\n",
      "Epoch 9: val_loss improved from 1.46953 to 1.25686, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 21ms/step - loss: 0.9943 - accuracy: 0.6572 - f1_m: 0.2757 - val_loss: 1.2569 - val_accuracy: 0.6053 - val_f1_m: 0.2980\n",
      "Epoch 10/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.9487 - accuracy: 0.6675 - f1_m: 0.2873\n",
      "Epoch 10: val_loss improved from 1.25686 to 1.19384, saving model to best_model.h5\n",
      "980/980 [==============================] - 21s 22ms/step - loss: 0.9487 - accuracy: 0.6675 - f1_m: 0.2873 - val_loss: 1.1938 - val_accuracy: 0.6535 - val_f1_m: 0.3106\n",
      "Epoch 11/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.9286 - accuracy: 0.6755 - f1_m: 0.2942\n",
      "Epoch 11: val_loss improved from 1.19384 to 1.06588, saving model to best_model.h5\n",
      "980/980 [==============================] - 21s 21ms/step - loss: 0.9286 - accuracy: 0.6755 - f1_m: 0.2942 - val_loss: 1.0659 - val_accuracy: 0.6613 - val_f1_m: 0.3215\n",
      "Epoch 12/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 0.8868 - accuracy: 0.6879 - f1_m: 0.3039\n",
      "Epoch 12: val_loss did not improve from 1.06588\n",
      "980/980 [==============================] - 21s 22ms/step - loss: 0.8869 - accuracy: 0.6879 - f1_m: 0.3039 - val_loss: 1.1461 - val_accuracy: 0.6623 - val_f1_m: 0.3267\n",
      "Epoch 13/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.8702 - accuracy: 0.6982 - f1_m: 0.3114\n",
      "Epoch 13: val_loss did not improve from 1.06588\n",
      "980/980 [==============================] - 21s 21ms/step - loss: 0.8702 - accuracy: 0.6983 - f1_m: 0.3114 - val_loss: 1.1483 - val_accuracy: 0.6695 - val_f1_m: 0.3346\n",
      "Epoch 14/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.8463 - accuracy: 0.7032 - f1_m: 0.3188\n",
      "Epoch 14: val_loss improved from 1.06588 to 1.06365, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 21ms/step - loss: 0.8463 - accuracy: 0.7031 - f1_m: 0.3188 - val_loss: 1.0636 - val_accuracy: 0.7016 - val_f1_m: 0.3484\n",
      "Epoch 15/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.8269 - accuracy: 0.7144 - f1_m: 0.3284\n",
      "Epoch 15: val_loss improved from 1.06365 to 0.98161, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 21ms/step - loss: 0.8271 - accuracy: 0.7144 - f1_m: 0.3284 - val_loss: 0.9816 - val_accuracy: 0.7178 - val_f1_m: 0.3483\n",
      "Epoch 16/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.8191 - accuracy: 0.7175 - f1_m: 0.3359\n",
      "Epoch 16: val_loss did not improve from 0.98161\n",
      "980/980 [==============================] - 21s 21ms/step - loss: 0.8190 - accuracy: 0.7176 - f1_m: 0.3359 - val_loss: 1.0074 - val_accuracy: 0.7029 - val_f1_m: 0.3597\n",
      "Epoch 17/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.8093 - accuracy: 0.7189 - f1_m: 0.3381\n",
      "Epoch 17: val_loss did not improve from 0.98161\n",
      "980/980 [==============================] - 21s 21ms/step - loss: 0.8090 - accuracy: 0.7189 - f1_m: 0.3381 - val_loss: 1.0398 - val_accuracy: 0.7118 - val_f1_m: 0.3557\n",
      "Epoch 18/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.7283 - f1_m: 0.3445\n",
      "Epoch 18: val_loss improved from 0.98161 to 0.92367, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 21ms/step - loss: 0.7916 - accuracy: 0.7283 - f1_m: 0.3445 - val_loss: 0.9237 - val_accuracy: 0.7363 - val_f1_m: 0.3647\n",
      "Epoch 19/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.7767 - accuracy: 0.7341 - f1_m: 0.3491\n",
      "Epoch 19: val_loss improved from 0.92367 to 0.88689, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 21ms/step - loss: 0.7766 - accuracy: 0.7341 - f1_m: 0.3491 - val_loss: 0.8869 - val_accuracy: 0.7390 - val_f1_m: 0.3787\n",
      "Epoch 20/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 0.7817 - accuracy: 0.7302 - f1_m: 0.3556\n",
      "Epoch 20: val_loss improved from 0.88689 to 0.86242, saving model to best_model.h5\n",
      "980/980 [==============================] - 20s 20ms/step - loss: 0.7816 - accuracy: 0.7303 - f1_m: 0.3556 - val_loss: 0.8624 - val_accuracy: 0.7415 - val_f1_m: 0.3729\n",
      "Epoch 21/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.7619 - accuracy: 0.7347 - f1_m: 0.3596\n",
      "Epoch 21: val_loss did not improve from 0.86242\n",
      "980/980 [==============================] - 18s 18ms/step - loss: 0.7619 - accuracy: 0.7347 - f1_m: 0.3596 - val_loss: 0.9754 - val_accuracy: 0.7415 - val_f1_m: 0.3829\n",
      "Epoch 22/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 0.7480 - accuracy: 0.7415 - f1_m: 0.3682\n",
      "Epoch 22: val_loss did not improve from 0.86242\n",
      "980/980 [==============================] - 18s 18ms/step - loss: 0.7480 - accuracy: 0.7414 - f1_m: 0.3683 - val_loss: 1.0026 - val_accuracy: 0.7251 - val_f1_m: 0.3921\n",
      "Epoch 23/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.7556 - accuracy: 0.7381 - f1_m: 0.3707\n",
      "Epoch 23: val_loss did not improve from 0.86242\n",
      "980/980 [==============================] - 17s 17ms/step - loss: 0.7550 - accuracy: 0.7383 - f1_m: 0.3709 - val_loss: 0.9484 - val_accuracy: 0.7378 - val_f1_m: 0.3907\n",
      "Epoch 24/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.7252 - accuracy: 0.7473 - f1_m: 0.3780\n",
      "Epoch 24: val_loss improved from 0.86242 to 0.77811, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 0.7249 - accuracy: 0.7473 - f1_m: 0.3780 - val_loss: 0.7781 - val_accuracy: 0.7535 - val_f1_m: 0.3920\n",
      "Epoch 25/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 0.7309 - accuracy: 0.7498 - f1_m: 0.3806\n",
      "Epoch 25: val_loss did not improve from 0.77811\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 0.7308 - accuracy: 0.7499 - f1_m: 0.3806 - val_loss: 0.7819 - val_accuracy: 0.7608 - val_f1_m: 0.4110\n",
      "Epoch 26/30\n",
      "978/980 [============================>.] - ETA: 0s - loss: 0.7091 - accuracy: 0.7533 - f1_m: 0.3908\n",
      "Epoch 26: val_loss did not improve from 0.77811\n",
      "980/980 [==============================] - 18s 19ms/step - loss: 0.7088 - accuracy: 0.7534 - f1_m: 0.3910 - val_loss: 0.7906 - val_accuracy: 0.7660 - val_f1_m: 0.3992\n",
      "Epoch 27/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.7568 - f1_m: 0.3918\n",
      "Epoch 27: val_loss did not improve from 0.77811\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 0.7032 - accuracy: 0.7568 - f1_m: 0.3918 - val_loss: 0.8861 - val_accuracy: 0.7487 - val_f1_m: 0.4189\n",
      "Epoch 28/30\n",
      "980/980 [============================>.] - ETA: 0s - loss: 0.6905 - accuracy: 0.7632 - f1_m: 0.4002\n",
      "Epoch 28: val_loss did not improve from 0.77811\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 0.6908 - accuracy: 0.7631 - f1_m: 0.4003 - val_loss: 0.8249 - val_accuracy: 0.7657 - val_f1_m: 0.4139\n",
      "Epoch 29/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.6972 - accuracy: 0.7602 - f1_m: 0.4023\n",
      "Epoch 29: val_loss improved from 0.77811 to 0.76233, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 20ms/step - loss: 0.6970 - accuracy: 0.7603 - f1_m: 0.4023 - val_loss: 0.7623 - val_accuracy: 0.7860 - val_f1_m: 0.4143\n",
      "Epoch 30/30\n",
      "979/980 [============================>.] - ETA: 0s - loss: 0.6897 - accuracy: 0.7629 - f1_m: 0.4085\n",
      "Epoch 30: val_loss improved from 0.76233 to 0.67332, saving model to best_model.h5\n",
      "980/980 [==============================] - 19s 19ms/step - loss: 0.6896 - accuracy: 0.7628 - f1_m: 0.4084 - val_loss: 0.6733 - val_accuracy: 0.7960 - val_f1_m: 0.4218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23da5517730>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (32,32,3)))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43 , activation = 'sigmoid'))\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  \n",
    "        samplewise_center=True,  \n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "save_model = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy',f1_m])\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "          steps_per_epoch=len(x_train) / 32, epochs=30, validation_data=(x_val, y_val), shuffle = True, callbacks=[save_model]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "981/981 [==============================] - 80s 81ms/step - loss: 0.3556 - accuracy: 0.9105 - f1_m: 0.9092 - val_loss: 0.0967 - val_accuracy: 0.9711 - val_f1_m: 0.9718\n",
      "Epoch 2/15\n",
      "981/981 [==============================] - 79s 80ms/step - loss: 0.0338 - accuracy: 0.9906 - f1_m: 0.9909 - val_loss: 0.0297 - val_accuracy: 0.9913 - val_f1_m: 0.9925\n",
      "Epoch 3/15\n",
      "981/981 [==============================] - 83s 85ms/step - loss: 0.0271 - accuracy: 0.9917 - f1_m: 0.9920 - val_loss: 0.0377 - val_accuracy: 0.9895 - val_f1_m: 0.9897\n",
      "Epoch 4/15\n",
      "981/981 [==============================] - 78s 79ms/step - loss: 0.0170 - accuracy: 0.9948 - f1_m: 0.9948 - val_loss: 0.0212 - val_accuracy: 0.9935 - val_f1_m: 0.9936\n",
      "Epoch 5/15\n",
      "981/981 [==============================] - 78s 79ms/step - loss: 0.0230 - accuracy: 0.9937 - f1_m: 0.9933 - val_loss: 0.0343 - val_accuracy: 0.9909 - val_f1_m: 0.9913\n",
      "Epoch 6/15\n",
      "981/981 [==============================] - 82s 84ms/step - loss: 0.0161 - accuracy: 0.9945 - f1_m: 0.9947 - val_loss: 0.0694 - val_accuracy: 0.9819 - val_f1_m: 0.9825\n",
      "Epoch 7/15\n",
      "981/981 [==============================] - 84s 86ms/step - loss: 0.0176 - accuracy: 0.9945 - f1_m: 0.9947 - val_loss: 0.0244 - val_accuracy: 0.9938 - val_f1_m: 0.9943\n",
      "Epoch 8/15\n",
      "981/981 [==============================] - 86s 87ms/step - loss: 0.0136 - accuracy: 0.9953 - f1_m: 0.9954 - val_loss: 0.0231 - val_accuracy: 0.9931 - val_f1_m: 0.9933\n",
      "Epoch 9/15\n",
      "981/981 [==============================] - 84s 85ms/step - loss: 0.0124 - accuracy: 0.9962 - f1_m: 0.9962 - val_loss: 0.0407 - val_accuracy: 0.9883 - val_f1_m: 0.9888\n",
      "Epoch 10/15\n",
      "981/981 [==============================] - 88s 89ms/step - loss: 0.0101 - accuracy: 0.9969 - f1_m: 0.9967 - val_loss: 0.0165 - val_accuracy: 0.9966 - val_f1_m: 0.9963\n",
      "Epoch 11/15\n",
      "981/981 [==============================] - 86s 87ms/step - loss: 0.0058 - accuracy: 0.9985 - f1_m: 0.9984 - val_loss: 0.0191 - val_accuracy: 0.9943 - val_f1_m: 0.9946\n",
      "Epoch 12/15\n",
      "981/981 [==============================] - 76s 77ms/step - loss: 0.0171 - accuracy: 0.9949 - f1_m: 0.9949 - val_loss: 0.0179 - val_accuracy: 0.9953 - val_f1_m: 0.9955\n",
      "Epoch 13/15\n",
      "981/981 [==============================] - 73s 74ms/step - loss: 0.0056 - accuracy: 0.9985 - f1_m: 0.9984 - val_loss: 0.0408 - val_accuracy: 0.9888 - val_f1_m: 0.9891\n",
      "Epoch 14/15\n",
      "981/981 [==============================] - 76s 78ms/step - loss: 0.0137 - accuracy: 0.9962 - f1_m: 0.9964 - val_loss: 0.0136 - val_accuracy: 0.9968 - val_f1_m: 0.9968\n",
      "Epoch 15/15\n",
      "981/981 [==============================] - 77s 78ms/step - loss: 0.0059 - accuracy: 0.9980 - f1_m: 0.9980 - val_loss: 0.0284 - val_accuracy: 0.9923 - val_f1_m: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d94102e60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (32,32,3)))\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(43 , activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , metrics=['accuracy',f1_m], optimizer = \"adam\")\n",
    "model.fit(x_train, y_train, epochs=15, verbose=1, validation_data=(x_val, y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture 2 + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 1.3138 - accuracy: 0.6324 - f1_m: 0.0962\n",
      "Epoch 1: val_loss improved from inf to 1.70102, saving model to best_model.h5\n",
      "980/980 [==============================] - 80s 81ms/step - loss: 1.3138 - accuracy: 0.6324 - f1_m: 0.0962 - val_loss: 1.7010 - val_accuracy: 0.5712 - val_f1_m: 0.0922\n",
      "Epoch 2/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.9078 - f1_m: 0.1005\n",
      "Epoch 2: val_loss improved from 1.70102 to 0.45467, saving model to best_model.h5\n",
      "980/980 [==============================] - 87s 89ms/step - loss: 0.2868 - accuracy: 0.9078 - f1_m: 0.1005 - val_loss: 0.4547 - val_accuracy: 0.8651 - val_f1_m: 0.0944\n",
      "Epoch 3/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9371 - f1_m: 0.1007\n",
      "Epoch 3: val_loss did not improve from 0.45467\n",
      "980/980 [==============================] - 101s 103ms/step - loss: 0.1900 - accuracy: 0.9371 - f1_m: 0.1007 - val_loss: 0.7944 - val_accuracy: 0.7777 - val_f1_m: 0.0871\n",
      "Epoch 4/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9451 - f1_m: 0.1005\n",
      "Epoch 4: val_loss did not improve from 0.45467\n",
      "980/980 [==============================] - 94s 96ms/step - loss: 0.1582 - accuracy: 0.9451 - f1_m: 0.1005 - val_loss: 0.6590 - val_accuracy: 0.8537 - val_f1_m: 0.0928\n",
      "Epoch 5/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9508 - f1_m: 0.1004\n",
      "Epoch 5: val_loss improved from 0.45467 to 0.20959, saving model to best_model.h5\n",
      "980/980 [==============================] - 90s 92ms/step - loss: 0.1304 - accuracy: 0.9508 - f1_m: 0.1004 - val_loss: 0.2096 - val_accuracy: 0.9257 - val_f1_m: 0.0952\n",
      "Epoch 6/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9507 - f1_m: 0.1004\n",
      "Epoch 6: val_loss did not improve from 0.20959\n",
      "980/980 [==============================] - 76s 77ms/step - loss: 0.1204 - accuracy: 0.9507 - f1_m: 0.1004 - val_loss: 0.7699 - val_accuracy: 0.8039 - val_f1_m: 0.0922\n",
      "Epoch 7/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9430 - f1_m: 0.1004\n",
      "Epoch 7: val_loss did not improve from 0.20959\n",
      "980/980 [==============================] - 85s 87ms/step - loss: 0.1304 - accuracy: 0.9430 - f1_m: 0.1004 - val_loss: 0.3443 - val_accuracy: 0.8942 - val_f1_m: 0.0945\n",
      "Epoch 8/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9436 - f1_m: 0.1008\n",
      "Epoch 8: val_loss improved from 0.20959 to 0.18158, saving model to best_model.h5\n",
      "980/980 [==============================] - 83s 85ms/step - loss: 0.1114 - accuracy: 0.9436 - f1_m: 0.1008 - val_loss: 0.1816 - val_accuracy: 0.9365 - val_f1_m: 0.0967\n",
      "Epoch 9/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9465 - f1_m: 0.1014\n",
      "Epoch 9: val_loss did not improve from 0.18158\n",
      "980/980 [==============================] - 88s 90ms/step - loss: 0.0873 - accuracy: 0.9465 - f1_m: 0.1014 - val_loss: 0.2650 - val_accuracy: 0.9132 - val_f1_m: 0.0902\n",
      "Epoch 10/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9415 - f1_m: 0.1015\n",
      "Epoch 10: val_loss did not improve from 0.18158\n",
      "980/980 [==============================] - 92s 94ms/step - loss: 0.0961 - accuracy: 0.9415 - f1_m: 0.1015 - val_loss: 0.2509 - val_accuracy: 0.9257 - val_f1_m: 0.0940\n",
      "Epoch 11/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9442 - f1_m: 0.1018\n",
      "Epoch 11: val_loss did not improve from 0.18158\n",
      "980/980 [==============================] - 91s 93ms/step - loss: 0.0805 - accuracy: 0.9442 - f1_m: 0.1018 - val_loss: 0.3213 - val_accuracy: 0.9079 - val_f1_m: 0.0943\n",
      "Epoch 12/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9421 - f1_m: 0.1021\n",
      "Epoch 12: val_loss improved from 0.18158 to 0.07927, saving model to best_model.h5\n",
      "980/980 [==============================] - 95s 97ms/step - loss: 0.0710 - accuracy: 0.9421 - f1_m: 0.1021 - val_loss: 0.0793 - val_accuracy: 0.9628 - val_f1_m: 0.1001\n",
      "Epoch 13/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9418 - f1_m: 0.1026\n",
      "Epoch 13: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 92s 94ms/step - loss: 0.0692 - accuracy: 0.9418 - f1_m: 0.1026 - val_loss: 0.1056 - val_accuracy: 0.9610 - val_f1_m: 0.0976\n",
      "Epoch 14/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9395 - f1_m: 0.1032\n",
      "Epoch 14: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 92s 94ms/step - loss: 0.0681 - accuracy: 0.9395 - f1_m: 0.1032 - val_loss: 0.7361 - val_accuracy: 0.8423 - val_f1_m: 0.0931\n",
      "Epoch 15/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9391 - f1_m: 0.1036\n",
      "Epoch 15: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 98s 100ms/step - loss: 0.0642 - accuracy: 0.9391 - f1_m: 0.1036 - val_loss: 0.2845 - val_accuracy: 0.9004 - val_f1_m: 0.1053\n",
      "Epoch 16/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9343 - f1_m: 0.1038\n",
      "Epoch 16: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 95s 97ms/step - loss: 0.0650 - accuracy: 0.9343 - f1_m: 0.1038 - val_loss: 0.1584 - val_accuracy: 0.9178 - val_f1_m: 0.1019\n",
      "Epoch 17/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9317 - f1_m: 0.1041\n",
      "Epoch 17: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 95s 97ms/step - loss: 0.0586 - accuracy: 0.9317 - f1_m: 0.1041 - val_loss: 0.3578 - val_accuracy: 0.9055 - val_f1_m: 0.0956\n",
      "Epoch 18/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9338 - f1_m: 0.1045\n",
      "Epoch 18: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 97s 99ms/step - loss: 0.0516 - accuracy: 0.9338 - f1_m: 0.1045 - val_loss: 0.1195 - val_accuracy: 0.9582 - val_f1_m: 0.1004\n",
      "Epoch 19/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9372 - f1_m: 0.1048\n",
      "Epoch 19: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 94s 95ms/step - loss: 0.0448 - accuracy: 0.9372 - f1_m: 0.1048 - val_loss: 0.0801 - val_accuracy: 0.9626 - val_f1_m: 0.1013\n",
      "Epoch 20/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9313 - f1_m: 0.1053\n",
      "Epoch 20: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 94s 95ms/step - loss: 0.0512 - accuracy: 0.9313 - f1_m: 0.1053 - val_loss: 0.6956 - val_accuracy: 0.8322 - val_f1_m: 0.0954\n",
      "Epoch 21/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9275 - f1_m: 0.1057\n",
      "Epoch 21: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 92s 94ms/step - loss: 0.0480 - accuracy: 0.9275 - f1_m: 0.1057 - val_loss: 0.1425 - val_accuracy: 0.9379 - val_f1_m: 0.1025\n",
      "Epoch 22/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9251 - f1_m: 0.1059\n",
      "Epoch 22: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 97s 99ms/step - loss: 0.0492 - accuracy: 0.9251 - f1_m: 0.1059 - val_loss: 0.9024 - val_accuracy: 0.7941 - val_f1_m: 0.0985\n",
      "Epoch 23/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9267 - f1_m: 0.1068\n",
      "Epoch 23: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 97s 99ms/step - loss: 0.0398 - accuracy: 0.9267 - f1_m: 0.1068 - val_loss: 0.1235 - val_accuracy: 0.9470 - val_f1_m: 0.0991\n",
      "Epoch 24/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9220 - f1_m: 0.1074\n",
      "Epoch 24: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 93s 94ms/step - loss: 0.0430 - accuracy: 0.9220 - f1_m: 0.1074 - val_loss: 0.3624 - val_accuracy: 0.8885 - val_f1_m: 0.1030\n",
      "Epoch 25/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9157 - f1_m: 0.1077\n",
      "Epoch 25: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 94s 96ms/step - loss: 0.0410 - accuracy: 0.9157 - f1_m: 0.1077 - val_loss: 0.1694 - val_accuracy: 0.9407 - val_f1_m: 0.0992\n",
      "Epoch 26/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9163 - f1_m: 0.1083\n",
      "Epoch 26: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 93s 95ms/step - loss: 0.0421 - accuracy: 0.9163 - f1_m: 0.1083 - val_loss: 0.3049 - val_accuracy: 0.8976 - val_f1_m: 0.0973\n",
      "Epoch 27/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9157 - f1_m: 0.1089\n",
      "Epoch 27: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 92s 94ms/step - loss: 0.0382 - accuracy: 0.9157 - f1_m: 0.1089 - val_loss: 0.1182 - val_accuracy: 0.9422 - val_f1_m: 0.1027\n",
      "Epoch 28/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9186 - f1_m: 0.1086\n",
      "Epoch 28: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 93s 95ms/step - loss: 0.0388 - accuracy: 0.9186 - f1_m: 0.1086 - val_loss: 0.6556 - val_accuracy: 0.8507 - val_f1_m: 0.0955\n",
      "Epoch 29/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9195 - f1_m: 0.1093\n",
      "Epoch 29: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 99s 101ms/step - loss: 0.0335 - accuracy: 0.9195 - f1_m: 0.1093 - val_loss: 0.5160 - val_accuracy: 0.8662 - val_f1_m: 0.0980\n",
      "Epoch 30/30\n",
      "981/980 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9200 - f1_m: 0.1105\n",
      "Epoch 30: val_loss did not improve from 0.07927\n",
      "980/980 [==============================] - 94s 96ms/step - loss: 0.0365 - accuracy: 0.9200 - f1_m: 0.1105 - val_loss: 0.1299 - val_accuracy: 0.9505 - val_f1_m: 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23db5dabeb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (32,32,3)))\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(43 , activation = 'sigmoid'))\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  \n",
    "        samplewise_center=True,  \n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=False) \n",
    "\n",
    "datagen.fit(x_train)\n",
    "save_model = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy',f1_m])\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "          steps_per_epoch=len(x_train) / 32, epochs=30, validation_data=(x_val, y_val), shuffle = True, callbacks=[save_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "* Architecture seems to play the biggest role when it comes to this dataset.\n",
    "* Transfer Learning and Data Augmentation doesn't seem to help with this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd0e7435bfd795f4447147e42b176d2d046fa2cc8c07720b9cd909dbd1a9c711"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
